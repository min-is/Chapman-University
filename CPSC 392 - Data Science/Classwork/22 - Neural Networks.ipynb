{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PzLHGCKvA5sS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.keras as kb\n",
        "from tensorflow.keras import backend\n",
        "import tensorflow as tf\n",
        "from plotnine import *\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "from sklearn.linear_model import LinearRegression # Linear Regression Model\n",
        "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
        "\n",
        "from sklearn.model_selection import train_test_split # simple TT split cv\n",
        "from sklearn.model_selection import KFold # k-fold cv\n",
        "from sklearn.model_selection import LeaveOneOut #LOO cv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoIvchZTA5sT"
      },
      "source": [
        "# 0. Together\n",
        "\n",
        "Neural Networks are great. Their flexibility (layers...connections...activation functions...and more!) allows you to build complex models that can accurately model complex relationships between predictors and outcomes. But I want to caution you: Neural Networks aren't magic. I often see people using them unnecessarily, just because they sound cool. If you're going to use NN's, make sure they're the right tool for your problem.\n",
        "\n",
        "\n",
        "When building a neural network you need to think about 2 (main) things:\n",
        "\n",
        "1. The Structure of the model (nodes/connections/activation functions)\n",
        "2. The Loss Function (how do we measure how well our model is doing?)\n",
        "\n",
        "\n",
        "# 1. Building a Simple NN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_FVK56nEA5sV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2553, 14)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/Music_data.csv\")\n",
        "feats = [\"danceability\", \"energy\", \"loudness\",\"acousticness\"]\n",
        "predict = \"valence\"\n",
        "\n",
        "print(df.shape)\n",
        "X = df[feats]\n",
        "y = df[predict]\n",
        "\n",
        "z = StandardScaler()\n",
        "\n",
        "X = z.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOvmCbAdA5sV"
      },
      "source": [
        "the model below has the same shape as a simple linear regression, like we talked about in lecture. It has an input layer with 4 inputs (\"danceability\", \"energy\", \"loudness\",\"acousticness\"), and 1 output layer for \"valence\".\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16JR3yX1gs7oC1isJAaJixNkrnZmdOxn1\" width = 800px />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F1_gnKbbA5sV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "80/80 [==============================] - 0s 745us/step - loss: 0.5952\n",
            "Epoch 2/5\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0718\n",
            "Epoch 3/5\n",
            "80/80 [==============================] - 0s 966us/step - loss: 0.0413\n",
            "Epoch 4/5\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0365\n",
            "Epoch 5/5\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0354\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x167493c70>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Regression\n",
        "\n",
        "#structure of the model\n",
        "model = kb.Sequential([\n",
        "    kb.layers.Dense(1, input_shape =[4]), #input\n",
        "])\n",
        "\n",
        "#how to train the model\n",
        "model.compile(loss = \"mean_squared_error\",\n",
        "              optimizer = kb.optimizers.SGD())\n",
        "\n",
        "#fit the model (same as SKlearn)\n",
        "model.fit(X,y, epochs = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "D01hUnk5A5sW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# build a linear regression model using LinearRegression and fitting on X and y (no need for model validation here)\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X, y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CLV4v8o2A5sW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 0.10576215],\n",
              "        [ 0.09453809],\n",
              "        [-0.0469894 ],\n",
              "        [ 0.01880122]], dtype=float32),\n",
              " array([0.47168404], dtype=float32)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get weights from Neural Network\n",
        "model.get_weights()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V5jTfmqRA5sX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.97748257 -0.27331087  0.55439531  0.76214928  0.73985534  3.72370251\n",
            "   1.60031525 -1.14207967  2.80331337]]\n"
          ]
        }
      ],
      "source": [
        "# get the coef_ and intercept_ from your linear regression model\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "print(lr.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofdQC5DIA5sX"
      },
      "source": [
        "### *Question*\n",
        "What happens to the weights from our neural net as you **increase** the number of epochs (compare to the coefs from the linear regression model)?\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpYaJ37JA5sX"
      },
      "source": [
        "# 2. Parameter Bloat\n",
        "\n",
        "Remember that a densely connected layer (`Dense()` in keras) is connected to EVERY node in the layer before and after it. The parameters can add up QUICKLY. Looking at the image of a densely connected, deep neural network below, try to calculate how many parameters (weights + bias) need to be estimates for that neural network (it's okay if you're off by a litte).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=19mh5qaqStcZzxir6fSWHkaiEtwMiVIVT\" width = 600px />\n",
        "\n",
        "### *Question*\n",
        "\n",
        "What do you think can happen when you have a ton of parameters and only a little data?\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />\n",
        "\n",
        "\n",
        "# 3. Building a Deep Neural Net\n",
        "\n",
        "Run the following model on the dataset `nn`. You can use `nn_test` as the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LxOTzWGbA5sZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 10) (50, 10)\n"
          ]
        }
      ],
      "source": [
        "nn = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/NN.csv\")\n",
        "nn_test = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/NN_test.csv\")\n",
        "\n",
        "X = nn[[\"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"]]\n",
        "y = nn[[\"V10\"]]\n",
        "\n",
        "X_test = nn_test[[\"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"]]\n",
        "y_test = nn_test[[\"V10\"]]\n",
        "\n",
        "\n",
        "print(nn.shape, nn_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F28ptsLJA5sZ"
      },
      "source": [
        "Build a Model with layers with 9,7,5,3,2,1 nodes respectively. Fill in the appropriate numbers to relace the `???`s. I've done the 9 and 7 for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0CL8KB7JA5sZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.6557\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 1.2901\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 1.1743\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0887\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0285\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9715\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9095\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8571\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8136\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7737\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7235\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6744\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6127\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5745\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5363\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5129\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4847\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4770\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4665\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4603\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4593\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4428\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4319\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4218\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4162\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4140\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4050\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4025\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3960\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3975\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3895\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3873\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3857\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3835\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3767\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3797\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3734\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3734\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3726\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3689\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3692\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3669\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3636\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3643\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3609\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3596\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3578\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3572\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3533\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3549\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3504\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3574\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3501\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3456\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3456\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3478\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3472\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3508\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3475\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3447\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3419\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3402\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3381\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3382\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3361\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3330\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3294\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3304\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3313\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3344\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3271\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3259\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3275\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3306\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3294\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3273\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3278\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3224\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3208\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3192\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3173\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3215\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3224\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3208\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3213\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3171\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3185\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3126\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3194\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3183\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3388\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3167\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3121\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3141\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3140\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3206\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3123\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3101\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3091\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3182\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x16bb72be0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## DEEP MODEL\n",
        "#structure of the model\n",
        "model2 = kb.Sequential([\n",
        "    kb.layers.Dense(7, input_shape =[9]), #input\n",
        "    kb.layers.Dense(5),\n",
        "    kb.layers.Dense(3),\n",
        "    kb.layers.Dense(2),\n",
        "    kb.layers.Dense(1) #output\n",
        "])\n",
        "#how to train the model\n",
        "model2.compile(loss = \"mean_squared_error\",\n",
        "              optimizer = kb.optimizers.SGD())\n",
        "\n",
        "#fit the model (same as SKlearn)\n",
        "model2.fit(X,y, epochs = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfHwxNHGA5sa"
      },
      "source": [
        "Now use `nn` and `nn_test`, and calculate the train and test MSEs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iNrbr-z5A5sa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3084673575396328\n",
            "0.37118254099971154\n"
          ]
        }
      ],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "y_pred_train = model2.predict(X)\n",
        "y_pred_test = model2.predict(X_test)\n",
        "\n",
        "print(mean_squared_error(y, y_pred_train))\n",
        "print(mean_squared_error(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amL-j-qOA5sa"
      },
      "source": [
        "# Other Random NN Topics That are Cool\n",
        "* Deep Neural Networks (NN's that have 2+ hidden layers)\n",
        "* Dropout (a way to regularize NNs)\n",
        "* Double Descent (You won't believe what this means for bias/variance tradedoff!!!)\n",
        "* Autoencoders (NN's that do non-linear PCA)\n",
        "* Generative Adversarial Networks (GANs; builds a model that can generate fake data, like faces, or paintings)\n",
        "* Recurrent Neural Networks (used for time series like sentences, music, stocks...even[harry potter](https://www.digitaltrends.com/cool-tech/harry-potter-ai-story/))\n",
        "* StyleGAN\n",
        "* Convolutional Neural Networks (often used for images, or other spatial data)\n",
        "* Shap values (a way to estimate the effect of different predictors in the NN)\n",
        "\n",
        "Check out [this video](https://www.youtube.com/watch?v=JBlm4wnjNMY) I wrote for Crash Course about Neural Nets."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "NeuralNetworks_Class24.ipynb",
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
